{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "015e40bc-fe42-4a4f-b92d-4e769c15ca8f",
   "metadata": {},
   "source": [
    "## 1. 字典研究\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0799451-05b6-420c-ac88-7c16b9534df1",
   "metadata": {},
   "source": [
    "### 1.1 用户评论 user reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0221424-29d1-438c-8e90-b5868e7940e4",
   "metadata": {},
   "source": [
    "- rating\t浮动型（float）\t产品评分（范围从 1.0 到 5.0）。\n",
    "- title\t字符串（str）\t用户评论的标题。\n",
    "- text\t字符串（str）\t用户评论的正文。\n",
    "- images\t列表（list）\t用户在收到产品后发布的图片。每张图片有不同的尺寸（小、中、大），分别由 small_image_url、medium_image_url 和 large_image_url 表示。\n",
    "- asin\t字符串（str）\t产品的 ID。\n",
    "- parent_asin\t字符串（str）\t产品的父 ID。注意：通常不同颜色、款式、尺寸的产品属于同一个父 ID。以前的 Amazon 数据集中的 asin 实际上是父 ID。请使用父 ID 来查找产品的元数据。\n",
    "- user_id\t字符串（str）\t评论者的 ID。\n",
    "- timestamp\t整数型（int）\t评论时间（Unix 时间戳）。\n",
    "- verified_purchase\t布尔型（bool）\t用户是否验证过购买。\n",
    "- helpful_vote\t整数型（int）\t评论的有用票数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1413dd-d751-465d-896b-9b90cc67e210",
   "metadata": {},
   "source": [
    "### 1.2 商品元数据 Item Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d0ee67-0905-4cbe-8e7d-2f01ebd30361",
   "metadata": {},
   "source": [
    "- main_category\t字符串（str）\t产品的主类目（即领域）。\n",
    "- title\t字符串（str）\t产品名称。\n",
    "- average_rating\t浮动型（float）\t产品页面显示的平均评分。\n",
    "- rating_number\t整数型（int）\t产品的评分数量。\n",
    "- features\t列表（list）\t产品的特点，以项目符号格式列出。\n",
    "- description\t列表（list）\t产品的描述。\n",
    "- price\t浮动型（float）\t产品的价格（以美元为单位）。\n",
    "- images\t列表（list）\t产品的图片。每张图片有不同的尺寸（缩略图、大图、高分辨率图）。variant 字段显示图片的版本。\n",
    "- videos\t列表（list）\t产品的视频，包括标题和 URL。\n",
    "- store\t字符串（str）\t产品的商店名称。\n",
    "- categories\t列表（list）\t产品的分层类别。\n",
    "- details\t字典（dict）\t产品详情，包括材料、品牌、尺寸等。\n",
    "- parent_asin\t字符串（str）\t产品的父 ID。\n",
    "- bought_together\t列表（list）\t网站推荐的搭配商品。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5cafbcfd-cccc-4e11-a581-3d7d751c3ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e49d325-c85a-45f6-89c0-6b565ac27adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据集\n",
    "dataset = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", \"raw_review_Amazon_Fashion\",\n",
    "                       trust_remote_code=True, cache_dir='./data/Amazon_Fashion/')\n",
    "meta_dataset = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", \"raw_meta_Amazon_Fashion\", split='full',\n",
    "                            trust_remote_code=True, cache_dir='./data/Amazon_Fashion/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebc0d6f4-1ac5-4ec4-8c54-bdd865bfef5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://m.media-amazon.com/images/I/41+cCfaVOFS._AC_.jpg', 'https://m.media-amazon.com/images/I/41jBdP7etRS._AC_.jpg', 'https://m.media-amazon.com/images/I/41UGJiRe7UL._AC_.jpg', 'https://m.media-amazon.com/images/I/41zb4GR-lWS._AC_.jpg', 'https://m.media-amazon.com/images/I/612BT4t-uFL._AC_.jpg', 'https://m.media-amazon.com/images/I/51ExLGv3QwL._AC_.jpg', 'https://m.media-amazon.com/images/I/313iU0xDEkS._AC_.jpg']\n"
     ]
    }
   ],
   "source": [
    "print(meta_dataset[0]['images']['large'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b3d2a54-e15a-4ac1-abd2-da31e5e5178f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "109f18e7-8f25-4898-9526-d203c63aab39",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 初始化 BERT 模型和 tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", cache_dir='./data/bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\", cache_dir='./data/bert-base-uncased-model')\n",
    "bert_model.eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4b3685f-350c-4c28-bd83-a8eee82ced01",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Identity()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 初始化 ResNet 模型\n",
    "resnet = models.resnet50(weights=True)\n",
    "resnet.fc = torch.nn.Identity()  # 去除全连接层，只保留特征提取部分\n",
    "resnet.eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da4e2f4f-c779-4b07-8409-0b138dd1a1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图像预处理\n",
    "img_preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f75ab5bf-1edb-44e6-935d-7e7c1b6b8954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 流式处理文本特征\n",
    "def extract_text_features(texts, batch_size=64, device='cuda'):\n",
    "    features = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        # 转换输入文本为 BERT 需要的格式\n",
    "        inputs = tokenizer(batch, padding=True, truncation=True, return_tensors=\"pt\", max_length=128)\n",
    "        \n",
    "        # 确保所有输入张量都在同一个设备上\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        \n",
    "        # 使用 BERT 模型\n",
    "        with torch.no_grad():\n",
    "            outputs = bert_model(**inputs)\n",
    "        \n",
    "        # 使用CLS token作为文本特征\n",
    "        cls_embeddings = outputs.last_hidden_state[:, 0, :].cpu()\n",
    "        features.append(cls_embeddings)\n",
    "    \n",
    "    return torch.cat(features, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39b3a29b-cdb5-44b1-b6e6-920e5de2b158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 流式处理图像特征\n",
    "def extract_image_feature(image_url, device='cuda'):\n",
    "    try:\n",
    "        response = requests.get(image_url)\n",
    "        image = Image.open(BytesIO(response.content)).convert('RGB')\n",
    "        img_tensor = img_preprocess(image).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            features = resnet(img_tensor).cpu()\n",
    "        return features.squeeze()\n",
    "    except:\n",
    "        return torch.zeros(2048)  # 空图像返回零向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbe56e9b-462b-4e60-9bdc-d1b3f6773a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 逐批处理数据\n",
    "def process_data(dataset, meta_dataset, batch_size=64):\n",
    "    all_text_features = []\n",
    "    all_image_features = []\n",
    "    \n",
    "    # 处理数据集中的文本和图像\n",
    "    for i in range(0, len(dataset), batch_size):\n",
    "        # 处理文本\n",
    "        batch_reviews = dataset[i:i+batch_size]['text']\n",
    "        text_features = extract_text_features(batch_reviews)\n",
    "        all_text_features.append(text_features)\n",
    "        \n",
    "    # 处理商品元数据中的图像\n",
    "    for i in range(0, len(meta_dataset), batch_size):\n",
    "        # 提取 large 图像\n",
    "        batch_meta = meta_dataset[i:i+batch_size]\n",
    "        image_urls = [meta['images']['large'] for meta in batch_meta if 'images' in meta and 'large' in meta['images']]\n",
    "        image_features = extract_image_features(image_urls)\n",
    "        all_image_features.append(image_features)\n",
    "    \n",
    "    # 将处理后的数据保存到文件\n",
    "    save_to_csv(all_text_features, all_image_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e1f182c-53a9-4fcf-baf7-c963c7575024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理数据并保存\n",
    "def process_and_save_data(dataset, meta_dataset, output_dir=\"./data/processed_data\"):\n",
    "    # 确保输出目录存在\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # 保存用户商品信息的 CSV 文件\n",
    "    user_item_info_file = os.path.join(output_dir, \"user_item_info.csv\")\n",
    "    with open(user_item_info_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "        fieldnames = [\"user_id\", \"asin\", \"parent_asin\", \"rating\", \"timestamp\", \"helpful_vote\"]\n",
    "        writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        # 处理前10000条评论（可调整）\n",
    "        for i in range(10000):\n",
    "            review = dataset['full'][i]\n",
    "            meta = meta_dataset[i]\n",
    "\n",
    "            # 提取文本特征\n",
    "            text_features = extract_text_features([review['text']], batch_size=64, device='cuda')\n",
    "\n",
    "            # 提取图像特征（如果有图像URL）\n",
    "            image_features = []\n",
    "            if 'images' in meta and 'large' in meta['images']:\n",
    "                image_urls = meta['images']['large']\n",
    "                image_features = extract_image_feature(image_urls[0], device='cuda')  # 只取第一个图像\n",
    "\n",
    "            # 写入用户和商品的信息\n",
    "            writer.writerow({\n",
    "                \"user_id\": review['user_id'],\n",
    "                \"asin\": review['asin'],\n",
    "                \"parent_asin\": review['parent_asin'],\n",
    "                \"rating\": review['rating'],\n",
    "                \"timestamp\": review['timestamp'],\n",
    "                \"helpful_vote\": review['helpful_vote']\n",
    "            })\n",
    "\n",
    "            # 保存文本特征和图像特征\n",
    "            # 存储文本特征为 .npy 文件\n",
    "            text_feature_file = os.path.join(output_dir, f\"text_features_{i}.npy\")\n",
    "            np.save(text_feature_file, text_features.squeeze().cpu().numpy())\n",
    "\n",
    "            # 存储图像特征为 .npy 文件\n",
    "            image_feature_file = os.path.join(output_dir, f\"image_features_{i}.npy\")\n",
    "            np.save(image_feature_file, image_features.cpu().numpy())\n",
    "\n",
    "            # 打印处理进度\n",
    "            if (i + 1) % 100 == 0:\n",
    "                print(f\"Processed {i + 1}/10000 records\")\n",
    "\n",
    "    print(f\"Processed data saved to {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "083defb2-14da-4349-9f12-aaed28bbdaa2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Features: tensor([[-1.5794e-01, -3.0994e-01,  5.1385e-01, -3.3866e-01, -1.0661e-01,\n",
      "         -2.8660e-01,  3.2009e-01,  6.5162e-01,  3.3201e-01, -4.5616e-01,\n",
      "          4.2836e-02, -2.2227e-01,  1.5335e-01,  4.6260e-01, -8.6974e-02,\n",
      "          2.2171e-01,  6.1301e-02,  7.0427e-01,  2.5363e-01,  4.0587e-02,\n",
      "         -2.4557e-01, -5.5593e-01,  5.3485e-01, -2.8614e-01,  2.0127e-02,\n",
      "          6.9144e-03, -3.4372e-01,  2.5355e-01,  5.4387e-02,  1.8149e-02,\n",
      "          1.6128e-01,  3.0740e-01, -5.3399e-01, -2.7201e-02,  9.6023e-01,\n",
      "         -9.0721e-02, -4.7360e-03,  5.2853e-02,  6.9606e-02, -4.9508e-02,\n",
      "         -2.9004e-01,  8.2307e-02,  4.2140e-01, -5.1297e-02, -4.1493e-02,\n",
      "         -5.5871e-01, -4.1468e+00,  1.9847e-01, -1.6316e-01, -2.3715e-01,\n",
      "          3.3993e-01, -5.1091e-01, -2.8263e-01,  4.3078e-01,  6.1901e-01,\n",
      "          4.4071e-01, -8.2627e-01,  1.1231e-01,  8.6912e-02, -1.3843e-01,\n",
      "          8.8562e-02, -1.9257e-01, -5.8624e-02,  1.6097e-01,  2.7554e-01,\n",
      "          2.9568e-01, -9.4417e-02, -8.7255e-02, -2.1233e-01,  4.4349e-01,\n",
      "         -2.8802e-01, -1.1504e-01,  4.6166e-01, -3.3727e-01, -2.3674e-01,\n",
      "         -3.6338e-01, -3.2247e-01,  3.6442e-01, -2.6845e-01,  3.4467e-01,\n",
      "         -1.0342e-01,  4.7472e-01,  1.9376e-01, -2.0133e-01,  8.1373e-02,\n",
      "          7.1081e-01, -3.7737e-01, -4.7762e-01, -2.2218e-01,  3.1914e-01,\n",
      "         -1.0648e-01, -3.7515e-03, -2.2971e-01,  5.4647e-01,  3.8620e-01,\n",
      "         -2.5146e-01, -1.5688e-01,  2.0798e-01,  6.0010e-01,  8.3688e-01,\n",
      "          3.2883e-01, -5.3289e-02, -1.6397e-01, -5.9382e-01,  9.5006e-02,\n",
      "         -4.6746e-02, -1.0989e-02, -1.4099e-01, -1.8391e-01, -1.6041e+00,\n",
      "          3.6460e-01,  7.0147e-02, -1.8591e-01, -1.3639e-02, -4.3363e-01,\n",
      "          4.7534e-01,  6.5794e-01,  7.6026e-02,  4.5644e-01,  7.0545e-01,\n",
      "          2.5234e-01, -1.7435e-01, -1.4253e-01, -3.0408e-01,  1.9392e-01,\n",
      "          4.6987e-01, -3.3934e-02,  2.0260e-01,  2.2836e-01,  4.8967e-01,\n",
      "          3.7474e-01,  6.7606e-01,  1.2931e-01, -1.7204e-01, -4.4420e-02,\n",
      "         -9.1616e-02,  1.8585e-01, -1.1149e-01, -2.4286e-01, -6.8371e-02,\n",
      "         -3.2035e-01, -3.3952e-01, -2.5508e+00,  4.6877e-01,  8.4108e-01,\n",
      "          3.0296e-01, -2.2292e-01, -4.8572e-02, -2.4057e-01, -2.8083e-01,\n",
      "          5.4186e-01,  2.0569e-01,  2.6186e-01, -2.5227e-01, -4.5765e-01,\n",
      "          1.4756e-01, -5.5282e-01, -3.5873e-01,  1.1256e-02,  1.6473e-01,\n",
      "          2.0254e-01,  1.1135e-01,  1.1732e-01,  1.5010e-01, -4.4601e-01,\n",
      "          3.7752e-01,  5.7198e-01,  9.5727e-01,  9.9770e-02, -3.2906e-02,\n",
      "         -3.3022e-01,  3.4037e-01,  2.2156e-01,  3.4484e-01, -3.3733e-02,\n",
      "         -3.1438e-01, -1.0463e-01,  5.6391e-01,  3.6225e-01, -1.4881e-01,\n",
      "         -5.5915e-01,  7.3799e-01,  8.2361e-02,  3.7655e-02,  4.1606e-02,\n",
      "         -6.1897e-02,  4.9958e-01,  2.6042e-01, -3.7092e-01, -1.6280e-01,\n",
      "         -4.8567e-01, -5.1428e-01,  4.5354e-01,  4.1698e-01,  5.7014e-01,\n",
      "         -1.0889e-01,  4.0797e-01, -2.7267e-01, -3.5802e-01,  5.0572e-01,\n",
      "          2.4877e-01,  1.4085e-02,  3.2895e-02, -1.0415e-01, -6.8396e-02,\n",
      "          3.7365e+00,  2.9950e-01, -1.0681e-01,  1.5375e-01,  3.0205e-01,\n",
      "         -1.3829e-02, -1.6719e-01, -2.3968e-01,  3.2490e-03,  3.9811e-01,\n",
      "          2.4441e-01,  5.5750e-01, -2.6238e-01,  2.0074e-01,  1.5414e-01,\n",
      "         -1.1200e-02,  3.6513e-01, -8.5647e-01,  7.9042e-01, -6.1327e-01,\n",
      "         -2.3839e-01, -3.2265e-01,  2.5402e-01,  2.0464e-01, -1.7567e+00,\n",
      "         -1.8659e-01, -3.4677e-01,  2.7913e-02,  3.9302e-01, -4.0868e-02,\n",
      "          1.3709e-01,  5.4946e-02, -3.3810e-01, -2.9953e-02, -1.8154e-01,\n",
      "          3.3526e-01,  5.6491e-01, -2.1502e-01,  3.0320e-01, -2.1318e-02,\n",
      "          9.0290e-01,  1.9566e-01, -2.9930e-01,  7.3790e-02, -8.4317e-01,\n",
      "          2.4217e-01,  2.3952e-01,  6.2147e-01, -1.3011e-02,  8.8504e-02,\n",
      "          5.0131e-02, -1.1807e-01,  6.3957e-02, -1.8976e-01, -2.1503e-01,\n",
      "         -3.6221e-01,  9.9763e-02, -1.5832e-02,  1.3269e-01, -1.3676e+00,\n",
      "         -4.6374e-01,  2.2451e-01,  8.3678e-02, -2.5920e-01, -9.5317e-02,\n",
      "         -2.6081e-02, -2.4060e-01, -5.2926e-01, -2.0287e+00,  5.4996e-03,\n",
      "         -4.3549e-01,  2.2022e-01,  4.5541e-01, -1.6919e-01,  2.5818e-01,\n",
      "          1.4313e-01,  6.0603e-01,  2.9959e-01,  3.8967e-01, -1.1521e-01,\n",
      "         -5.3668e-01,  4.5622e-01, -4.4446e-01, -2.2082e-01, -3.9774e-01,\n",
      "         -6.9294e-02, -2.4419e-01, -3.5816e-01,  1.3314e-01,  2.8659e-01,\n",
      "         -5.3439e-01,  3.2278e-01,  5.7643e-01,  1.8651e-01, -1.9986e-01,\n",
      "         -2.2621e-01,  4.2996e-01,  1.9337e-01,  2.8781e-01,  5.1716e-03,\n",
      "          4.8990e-01, -2.5078e-01, -4.3536e-01, -3.7115e+00,  7.2793e-02,\n",
      "         -5.0535e-01, -1.9413e-01, -1.2843e-01, -2.3733e-01,  5.0262e-01,\n",
      "         -2.1042e-01, -5.9331e-01, -2.6501e-01,  7.2607e-01,  1.1669e-01,\n",
      "          3.7698e-02, -4.5768e-02,  3.6714e-01,  5.0717e-01,  5.9963e-01,\n",
      "         -1.4936e-01,  1.8645e-01,  1.2638e-01, -2.5546e-01,  3.7502e-01,\n",
      "         -5.4683e-03, -2.2153e-01,  7.0546e-01,  4.1868e-01, -4.0837e-01,\n",
      "         -4.2659e-01,  1.3283e-02,  1.1007e-01, -1.4655e-01, -1.0312e-01,\n",
      "          2.1649e-02, -6.5739e-01, -2.2487e-01, -4.1645e-01,  4.4870e-01,\n",
      "         -1.4355e-01,  3.8353e-01, -2.9469e-01, -1.3593e-01,  4.3798e-01,\n",
      "          9.1487e-02,  2.8200e-01,  6.9022e-01, -1.6752e-01,  6.4194e-01,\n",
      "         -1.4989e-01, -1.1305e-01,  3.0792e-01,  3.9325e-02, -1.5933e-01,\n",
      "          9.6836e-01, -3.6865e-01, -4.7551e-02,  4.6759e-02,  2.8110e-01,\n",
      "          5.9583e-01, -8.8837e-02,  3.5327e-01,  3.7255e-02, -2.8792e-01,\n",
      "         -1.8258e-03, -8.0929e-01, -5.6649e-02, -1.4668e-01,  3.7253e-01,\n",
      "         -7.8284e-01,  9.9368e-02,  3.0827e-01,  1.6150e-01,  4.1563e-01,\n",
      "         -5.1306e-01, -1.4571e+00,  1.3833e-01,  1.5024e-04, -4.2204e-01,\n",
      "          1.6994e-01, -5.3783e-02,  2.0295e-01, -2.3788e-01, -3.7926e-01,\n",
      "         -2.4081e-02,  7.6003e-01, -4.7026e-01, -1.3276e-01,  2.1797e-01,\n",
      "          4.4136e-02, -8.5591e-01, -8.7301e-02,  3.3456e-01,  3.3364e-01,\n",
      "          3.6793e-02,  2.8290e-01, -4.8308e-01, -1.2447e-01,  5.2854e-01,\n",
      "         -1.3996e+00,  3.5603e-01, -8.4319e-01,  4.6230e-01,  2.0334e-01,\n",
      "          2.4256e-01, -3.8084e-01, -1.2084e-01, -2.6390e-01, -3.2191e-02,\n",
      "          3.1342e-01,  6.0658e-01, -3.8162e-01, -5.1786e-01, -4.2540e-01,\n",
      "          2.7391e-01, -4.2908e-02,  7.8206e-01, -5.4817e-01,  8.0313e-02,\n",
      "          4.0461e-01, -2.7607e-01, -2.3861e-01,  7.7142e-01,  4.0227e-01,\n",
      "          4.9270e-02, -5.5197e-01, -7.0941e-01,  1.1909e-02,  1.2578e-02,\n",
      "         -1.1136e-01, -7.0266e-01,  2.6960e-01,  2.1927e-01, -3.7338e-01,\n",
      "         -7.2270e-01, -1.9012e-01, -1.3563e-01,  1.3536e-02, -2.6339e-01,\n",
      "         -1.5289e-01,  3.7251e-01, -8.6993e-02,  6.4375e-01, -3.0157e-01,\n",
      "         -4.6252e-01,  3.0271e-01, -6.7774e-02,  6.2604e-01, -5.9339e-02,\n",
      "          1.1245e-01, -2.1023e-01,  2.5598e-01, -3.5059e-02, -1.1900e-01,\n",
      "         -2.9951e-01, -6.6223e-01,  2.4362e-01,  1.9981e-01, -4.5617e-01,\n",
      "          2.1856e-02, -2.9450e-01,  1.5869e-02,  1.6645e-01,  4.5358e-02,\n",
      "         -1.7532e+00,  5.7992e-01,  6.6633e-01,  5.0381e-01,  2.7389e-01,\n",
      "         -3.4619e-01, -2.3197e-01,  7.5747e-01,  2.0924e-01,  2.4752e-01,\n",
      "         -7.2626e-01,  1.3694e-01,  3.2386e-01,  3.8397e-01,  4.7701e-02,\n",
      "         -1.7016e-01, -2.9816e-01, -4.3773e-01,  2.6027e-01, -7.4136e-01,\n",
      "         -4.7871e-02,  1.1452e-01,  2.1302e-01,  7.1452e-02,  1.7804e-01,\n",
      "         -5.0387e-01, -2.7818e-01,  8.6751e-01,  1.7658e-01,  4.9278e-01,\n",
      "         -2.7838e-01, -4.6531e-01, -5.7145e-01, -2.3326e-01,  1.2201e-01,\n",
      "          2.4968e-01, -2.7538e-02, -5.7702e-01,  4.2138e-01,  7.8225e-01,\n",
      "         -6.8663e-01,  5.7592e-01,  4.2980e-01,  1.8009e-01,  6.0364e-01,\n",
      "          6.4328e-01, -2.2956e-01,  5.2879e-01,  1.1070e-01, -6.6083e-01,\n",
      "         -3.2211e-01, -6.1433e-01, -1.0439e+00, -1.3094e-01, -2.5673e-01,\n",
      "         -4.7394e-01, -1.5745e-01,  7.6527e-02, -6.5454e-01, -1.6924e-01,\n",
      "          3.2341e-01, -7.6158e-01, -8.9188e-01,  2.9908e-03, -3.6858e-03,\n",
      "         -6.4831e-01, -8.8980e-02, -3.5200e-01, -5.3612e-01,  3.4896e-01,\n",
      "          9.9758e-01, -9.7144e-02, -6.1413e-01,  3.6949e-01, -6.0855e-01,\n",
      "          2.3683e-01, -8.0884e-02,  7.8557e-02,  2.1783e-01, -4.1634e-01,\n",
      "         -1.6483e-01, -1.2388e-01, -5.1090e-01,  3.6329e-01, -2.2635e-01,\n",
      "          2.0867e-01, -7.1897e-01,  2.7495e-01,  1.0812e-01, -2.7862e-01,\n",
      "         -3.5142e-01, -4.8333e-01,  2.7490e-01, -2.9277e-01,  1.1868e-01,\n",
      "          2.6034e-01,  2.1043e-01, -1.5665e-01, -1.9182e-01, -3.2414e-01,\n",
      "         -2.8165e-01,  2.7375e-01,  6.3864e-01,  3.2483e-01,  2.4502e-01,\n",
      "          1.6799e-01,  4.8955e-01, -2.9113e-01,  3.4313e-02, -2.3622e-01,\n",
      "          6.6021e-01, -6.0790e-01, -2.0165e-01, -2.5735e-02, -7.2894e-03,\n",
      "         -7.2138e-01,  5.0538e-01, -5.2012e-01,  1.8503e+00,  1.7410e-01,\n",
      "          4.5455e-01, -3.1393e-01,  2.9701e-01, -2.6104e-01, -4.0514e-01,\n",
      "          3.7662e-01, -1.3143e-01,  6.8968e-01, -1.7136e-01,  5.2285e-01,\n",
      "         -6.0399e-01, -2.0419e-01,  3.5533e-01,  1.9197e-01, -1.8205e-01,\n",
      "          3.4370e-02, -5.1144e-01,  2.9220e-01, -3.6244e-01,  7.1482e-01,\n",
      "          6.1391e-01,  1.4025e-01,  2.3928e-01,  5.9847e-01,  2.8537e-01,\n",
      "         -4.9447e-02,  4.6053e-01,  1.2296e+00, -5.0635e-01, -1.6342e-02,\n",
      "          4.1877e-01,  2.6970e-01, -8.2766e-01, -2.5103e-01, -4.4685e-01,\n",
      "         -2.4474e-01, -3.9035e-02,  1.3352e-01,  4.1818e-01, -5.4028e-01,\n",
      "          6.8456e-01, -2.5714e-01, -8.9664e-01,  6.0326e-01, -6.5654e-01,\n",
      "         -2.1042e-01,  9.2318e-01,  4.0860e-01,  4.5648e-01,  1.6527e-01,\n",
      "         -3.8264e-01,  1.1212e-01,  2.9232e-01, -1.7819e-01, -4.4733e-01,\n",
      "         -1.9169e-01, -1.3981e-01,  4.8919e-01, -1.2172e-01,  7.7384e-03,\n",
      "          3.0675e-01, -4.5407e-01,  2.1659e-01,  3.6623e-01,  1.0018e-01,\n",
      "          1.7722e-01,  4.8498e-01, -6.7645e-01,  7.3568e-02,  6.3765e-01,\n",
      "          1.3329e-01,  3.5086e-01,  1.9595e-01,  4.6945e-01,  1.8448e-01,\n",
      "         -1.1038e-02, -8.1706e-01, -1.6549e+00,  2.5399e-01,  2.5299e-01,\n",
      "          1.8252e-01,  5.0239e-01, -2.0798e-01,  6.8250e-01, -5.4888e-02,\n",
      "          1.3722e-01, -1.4838e-01,  4.9074e-01,  2.8848e-01,  3.8041e-01,\n",
      "         -1.4377e-01,  3.5973e-01,  5.0773e-02,  2.7667e-01, -3.0878e-01,\n",
      "          1.9065e-01, -4.1023e-01,  2.0400e-01,  1.4704e-01, -7.3063e-02,\n",
      "         -2.3932e-01, -7.1601e-01,  5.4547e-02, -3.9250e-01, -2.9649e-01,\n",
      "          1.4427e-01,  2.2146e-01, -1.1218e-01,  6.2672e-01, -2.1476e-01,\n",
      "         -2.7257e-01,  1.1878e-02, -1.3984e-01, -5.5675e-01,  4.2108e-01,\n",
      "          1.0537e-01, -5.3382e-02, -2.8481e-01,  6.2781e-01, -2.1821e-01,\n",
      "          5.0151e-01,  5.1687e-01, -4.1612e-01,  7.7447e-01, -3.4425e-01,\n",
      "          5.8283e-01, -4.7576e-01, -6.4400e-02, -1.2865e-01,  6.2359e-01,\n",
      "          2.2015e-01,  1.8868e-01,  3.6234e-01,  2.8102e-01,  2.7549e-01,\n",
      "          2.7241e-01, -6.4587e-01, -1.7617e-01,  2.4070e-01, -5.8816e-01,\n",
      "          4.2012e-02,  5.9333e-01,  6.6788e-02, -1.6614e-01,  3.5677e-01,\n",
      "         -3.0580e-01, -4.0823e-01, -7.2509e-01, -1.1820e-01,  7.2580e-01,\n",
      "          4.1693e-01, -2.7688e-02, -4.9899e-01,  5.2029e-01, -1.8355e-01,\n",
      "          2.8438e-01, -1.0678e-01, -2.2588e-01,  4.3828e-02, -1.4959e-02,\n",
      "         -3.0487e-01,  3.0835e-01, -5.3999e+00, -5.2422e-02, -3.0221e-01,\n",
      "         -5.6264e-01, -2.1567e-01, -8.3814e-01, -2.7773e-01, -5.3552e-01,\n",
      "          3.0943e-01, -2.2637e-01, -8.2001e-02,  1.1458e-01, -2.0247e-01,\n",
      "         -6.1487e-02, -2.6053e-02,  3.9421e-01]]) torch.Size([1, 768])\n",
      "Image Features: tensor([0.3001, 0.7368, 0.0248,  ..., 0.2291, 0.5109, 0.1767]) torch.Size([2048])\n"
     ]
    }
   ],
   "source": [
    "# 测试处理单条数据\n",
    "review = dataset['full'][0]\n",
    "meta = meta_dataset[0]\n",
    "\n",
    "text_features = extract_text_features([review['text']], batch_size=1, device='cuda')\n",
    "image_features = []\n",
    "if 'images' in meta and 'large' in meta['images']:\n",
    "    image_urls = meta['images']['large']\n",
    "    image_features = extract_image_feature(image_urls[0], device='cuda')\n",
    "\n",
    "# 打印处理的特征\n",
    "print(\"Text Features:\", text_features, text_features.shape)\n",
    "print(\"Image Features:\", image_features, image_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "105398f6-36de-4778-a90f-168a85938601",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100/10000 records\n",
      "Processed 200/10000 records\n",
      "Processed 300/10000 records\n",
      "Processed 400/10000 records\n",
      "Processed 500/10000 records\n",
      "Processed 600/10000 records\n",
      "Processed 700/10000 records\n",
      "Processed 800/10000 records\n",
      "Processed 900/10000 records\n",
      "Processed 1000/10000 records\n",
      "Processed 1100/10000 records\n",
      "Processed 1200/10000 records\n",
      "Processed 1300/10000 records\n",
      "Processed 1400/10000 records\n",
      "Processed 1500/10000 records\n",
      "Processed 1600/10000 records\n",
      "Processed 1700/10000 records\n",
      "Processed 1800/10000 records\n",
      "Processed 1900/10000 records\n",
      "Processed 2000/10000 records\n",
      "Processed 2100/10000 records\n",
      "Processed 2200/10000 records\n",
      "Processed 2300/10000 records\n",
      "Processed 2400/10000 records\n",
      "Processed 2500/10000 records\n",
      "Processed 2600/10000 records\n",
      "Processed 2700/10000 records\n",
      "Processed 2800/10000 records\n",
      "Processed 2900/10000 records\n",
      "Processed 3000/10000 records\n",
      "Processed 3100/10000 records\n",
      "Processed 3200/10000 records\n",
      "Processed 3300/10000 records\n",
      "Processed 3400/10000 records\n",
      "Processed 3500/10000 records\n",
      "Processed 3600/10000 records\n",
      "Processed 3700/10000 records\n",
      "Processed 3800/10000 records\n",
      "Processed 3900/10000 records\n",
      "Processed 4000/10000 records\n",
      "Processed 4100/10000 records\n",
      "Processed 4200/10000 records\n",
      "Processed 4300/10000 records\n",
      "Processed 4400/10000 records\n",
      "Processed 4500/10000 records\n",
      "Processed 4600/10000 records\n",
      "Processed 4700/10000 records\n",
      "Processed 4800/10000 records\n",
      "Processed 4900/10000 records\n",
      "Processed 5000/10000 records\n",
      "Processed 5100/10000 records\n",
      "Processed 5200/10000 records\n",
      "Processed 5300/10000 records\n",
      "Processed 5400/10000 records\n",
      "Processed 5500/10000 records\n",
      "Processed 5600/10000 records\n",
      "Processed 5700/10000 records\n",
      "Processed 5800/10000 records\n",
      "Processed 5900/10000 records\n",
      "Processed 6000/10000 records\n",
      "Processed 6100/10000 records\n",
      "Processed 6200/10000 records\n",
      "Processed 6300/10000 records\n",
      "Processed 6400/10000 records\n",
      "Processed 6500/10000 records\n",
      "Processed 6600/10000 records\n",
      "Processed 6700/10000 records\n",
      "Processed 6800/10000 records\n",
      "Processed 6900/10000 records\n",
      "Processed 7000/10000 records\n",
      "Processed 7100/10000 records\n",
      "Processed 7200/10000 records\n",
      "Processed 7300/10000 records\n",
      "Processed 7400/10000 records\n",
      "Processed 7500/10000 records\n",
      "Processed 7600/10000 records\n",
      "Processed 7700/10000 records\n",
      "Processed 7800/10000 records\n",
      "Processed 7900/10000 records\n",
      "Processed 8000/10000 records\n",
      "Processed 8100/10000 records\n",
      "Processed 8200/10000 records\n",
      "Processed 8300/10000 records\n",
      "Processed 8400/10000 records\n",
      "Processed 8500/10000 records\n",
      "Processed 8600/10000 records\n",
      "Processed 8700/10000 records\n",
      "Processed 8800/10000 records\n",
      "Processed 8900/10000 records\n",
      "Processed 9000/10000 records\n",
      "Processed 9100/10000 records\n",
      "Processed 9200/10000 records\n",
      "Processed 9300/10000 records\n",
      "Processed 9400/10000 records\n",
      "Processed 9500/10000 records\n",
      "Processed 9600/10000 records\n",
      "Processed 9700/10000 records\n",
      "Processed 9800/10000 records\n",
      "Processed 9900/10000 records\n",
      "Processed 10000/10000 records\n",
      "Processed data saved to ./data/processed_data\n"
     ]
    }
   ],
   "source": [
    "# 开始处理并保存数据\n",
    "process_and_save_data(dataset, meta_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4e9c58-c867-4436-af86-7caba3b6cd17",
   "metadata": {},
   "source": [
    "## 2. 利用特征数据进行建模和推荐算法设计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c655f358-7fd7-45e0-99c6-1a4ebec29d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c09e248-3ba4-4bc3-ae3b-d627428ad978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载 CSV 文件\n",
    "df = pd.read_csv(\"./data/processed_data/user_item_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20788063-1957-450a-8300-9c8fbacbd3a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>asin</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>helpful_vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGBFYI2DDIKXC5Y4FARTYDTQBMFQ</td>\n",
       "      <td>B00LOPVX74</td>\n",
       "      <td>B00LOPVX74</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1578528394489</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFQLNQNQYFWQZPJQZS6V3NZU4QBQ</td>\n",
       "      <td>B07B4JXK8D</td>\n",
       "      <td>B07B4JXK8D</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1608426246701</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AHITBJSS7KYUBVZPX7M2WJCOIVKQ</td>\n",
       "      <td>B007ZSEQ4Q</td>\n",
       "      <td>B007ZSEQ4Q</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1432344828000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFVNEEPDEIH5SPUN5BWC6NKL3WNQ</td>\n",
       "      <td>B07F2BTFS9</td>\n",
       "      <td>B07F2BTFS9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1546289847095</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AHSPLDNW5OOUK2PLH7GXLACFBZNQ</td>\n",
       "      <td>B00PKRFU4O</td>\n",
       "      <td>B00XESJTDE</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1439476166000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        user_id        asin parent_asin  rating  \\\n",
       "0  AGBFYI2DDIKXC5Y4FARTYDTQBMFQ  B00LOPVX74  B00LOPVX74     5.0   \n",
       "1  AFQLNQNQYFWQZPJQZS6V3NZU4QBQ  B07B4JXK8D  B07B4JXK8D     5.0   \n",
       "2  AHITBJSS7KYUBVZPX7M2WJCOIVKQ  B007ZSEQ4Q  B007ZSEQ4Q     2.0   \n",
       "3  AFVNEEPDEIH5SPUN5BWC6NKL3WNQ  B07F2BTFS9  B07F2BTFS9     1.0   \n",
       "4  AHSPLDNW5OOUK2PLH7GXLACFBZNQ  B00PKRFU4O  B00XESJTDE     5.0   \n",
       "\n",
       "       timestamp  helpful_vote  \n",
       "0  1578528394489             3  \n",
       "1  1608426246701             0  \n",
       "2  1432344828000             3  \n",
       "3  1546289847095             2  \n",
       "4  1439476166000             0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1cfd3c10-cab2-4889-af61-4e42a49f4470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用LabelEncoder对用户ID和商品ID进行编码\n",
    "user_encoder = LabelEncoder()\n",
    "df['user_idx'] = user_encoder.fit_transform(df['user_id'])\n",
    "\n",
    "product_encoder = LabelEncoder()\n",
    "df['product_idx'] = product_encoder.fit_transform(df['asin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d060768-0c59-4be6-b677-607de2ca7b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>asin</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>helpful_vote</th>\n",
       "      <th>user_idx</th>\n",
       "      <th>product_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGBFYI2DDIKXC5Y4FARTYDTQBMFQ</td>\n",
       "      <td>B00LOPVX74</td>\n",
       "      <td>B00LOPVX74</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1578528394489</td>\n",
       "      <td>3</td>\n",
       "      <td>2349</td>\n",
       "      <td>562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFQLNQNQYFWQZPJQZS6V3NZU4QBQ</td>\n",
       "      <td>B07B4JXK8D</td>\n",
       "      <td>B07B4JXK8D</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1608426246701</td>\n",
       "      <td>0</td>\n",
       "      <td>1789</td>\n",
       "      <td>3724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AHITBJSS7KYUBVZPX7M2WJCOIVKQ</td>\n",
       "      <td>B007ZSEQ4Q</td>\n",
       "      <td>B007ZSEQ4Q</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1432344828000</td>\n",
       "      <td>3</td>\n",
       "      <td>3561</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFVNEEPDEIH5SPUN5BWC6NKL3WNQ</td>\n",
       "      <td>B07F2BTFS9</td>\n",
       "      <td>B07F2BTFS9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1546289847095</td>\n",
       "      <td>2</td>\n",
       "      <td>1946</td>\n",
       "      <td>4131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AHSPLDNW5OOUK2PLH7GXLACFBZNQ</td>\n",
       "      <td>B00PKRFU4O</td>\n",
       "      <td>B00XESJTDE</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1439476166000</td>\n",
       "      <td>0</td>\n",
       "      <td>3857</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        user_id        asin parent_asin  rating  \\\n",
       "0  AGBFYI2DDIKXC5Y4FARTYDTQBMFQ  B00LOPVX74  B00LOPVX74     5.0   \n",
       "1  AFQLNQNQYFWQZPJQZS6V3NZU4QBQ  B07B4JXK8D  B07B4JXK8D     5.0   \n",
       "2  AHITBJSS7KYUBVZPX7M2WJCOIVKQ  B007ZSEQ4Q  B007ZSEQ4Q     2.0   \n",
       "3  AFVNEEPDEIH5SPUN5BWC6NKL3WNQ  B07F2BTFS9  B07F2BTFS9     1.0   \n",
       "4  AHSPLDNW5OOUK2PLH7GXLACFBZNQ  B00PKRFU4O  B00XESJTDE     5.0   \n",
       "\n",
       "       timestamp  helpful_vote  user_idx  product_idx  \n",
       "0  1578528394489             3      2349          562  \n",
       "1  1608426246701             0      1789         3724  \n",
       "2  1432344828000             3      3561          194  \n",
       "3  1546289847095             2      1946         4131  \n",
       "4  1439476166000             0      3857          701  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "803ec5a0-e04e-493d-a8c4-1c369a1568ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge index: (2, 10000)\n",
      "Edge label: torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "# 创建边（edges）\n",
    "edge_index = torch.tensor([df['user_idx'].values, df['product_idx'].values + df['user_idx'].nunique()], dtype=torch.long)\n",
    "\n",
    "edge_label = torch.tensor(df['rating'].values, dtype=torch.float32)\n",
    "\n",
    "# 打印边的信息\n",
    "print(\"Edge index:\", edges.shape)\n",
    "print(\"Edge label:\", edge_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "39894cbb-16a2-4afd-9262-5f85e54234f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text features shape: (10000, 768)\n",
      "Image features shape: (10000, 2048)\n"
     ]
    }
   ],
   "source": [
    "# 设定文件夹路径\n",
    "data_dir = './data/processed_data'\n",
    "\n",
    "# 获取文件夹内所有的 .npy 文件名\n",
    "text_files = sorted([f for f in os.listdir(data_dir) if 'text_features' in f and f.endswith('.npy')])\n",
    "image_files = sorted([f for f in os.listdir(data_dir) if 'image_features' in f and f.endswith('.npy')])\n",
    "\n",
    "# 初始化用于存储特征的列表\n",
    "text_features_list = []\n",
    "image_features_list = []\n",
    "\n",
    "# 加载所有的 text_features 和 image_features\n",
    "for text_file, image_file in zip(text_files, image_files):\n",
    "    text_feature = np.load(os.path.join(data_dir, text_file))  # 加载文本特征\n",
    "    image_feature = np.load(os.path.join(data_dir, image_file))  # 加载图像特征\n",
    "    \n",
    "    text_features_list.append(text_feature)\n",
    "    image_features_list.append(image_feature)\n",
    "\n",
    "# 将所有的特征合并为一个大的 numpy 数组\n",
    "text_features = np.stack(text_features_list, axis=0)\n",
    "image_features = np.stack(image_features_list, axis=0)\n",
    "\n",
    "print(f\"Text features shape: {text_features.shape}\")\n",
    "print(f\"Image features shape: {image_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8e8289dd-69bf-4719-a018-91a6af0db47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并 text_features、image_features 和 user_features\n",
    "item_features = np.concatenate([text_features, image_features], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "23bfbbb9-2fd9-493d-b356-b4760e78c981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2816)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "044e5b20-624b-4992-876a-717446fe26ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造 user 节点的特征\n",
    "num_users = df['user_idx'].nunique()\n",
    "user_features = np.zeros((num_users, item_features.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c044b4a5-5560-49b0-8957-8b1fef46c8ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4086, 2816)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a15ff883-9d73-4b49-a0de-3e9ec1c57bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拼接 user 和 item 节点特征\n",
    "x = torch.tensor(np.vstack([user_features, item_features]), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0ad9fae4-101f-44ab-8df6-b669ecb31519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_time_features(df, ts_col='timestamp'):\n",
    "    # 转换为 datetime 格式（注意是毫秒）\n",
    "    df['dt'] = df[ts_col].apply(lambda x: datetime.fromtimestamp(x / 1000))\n",
    "    \n",
    "    # 提取年（减去最小年份后再归一化）\n",
    "    df['year'] = df['dt'].dt.year\n",
    "    df['year'] = (df['year'] - df['year'].min()) / (df['year'].max() - df['year'].min())\n",
    "\n",
    "    # 月（1~12）\n",
    "    df['month'] = (df['dt'].dt.month - 1) / 11.0\n",
    "\n",
    "    # 周（0=Monday, 6=Sunday）\n",
    "    df['weekday'] = df['dt'].dt.weekday / 6.0\n",
    "\n",
    "    # 小时（0~23）\n",
    "    df['hour'] = df['dt'].dt.hour / 23.0\n",
    "\n",
    "    return df[['year', 'month', 'weekday', 'hour']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c7bbcc13-2feb-47c7-8879-100dbdfad9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 提取边的时间特征\n",
    "time_features = extract_time_features(df)  # df 为你的边信息 DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "842c65c9-bd48-4fa0-8fbd-4d456eb4d1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 提取 helpful_votes\n",
    "helpful = df['helpful_vote'].values.reshape(-1, 1)\n",
    "helpful = (helpful - helpful.min()) / (helpful.max() - helpful.min())  # 归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "496ec000-e8aa-45c3-adef-d84c6ee5dae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 拼接所有边特征\n",
    "edge_attr = np.hstack([time_features.values, helpful])\n",
    "edge_attr = torch.tensor(edge_attr, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "1acf5c5c-46f5-43d2-a562-39efd905d21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, edge_label=edge_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "22ea103f-e703-478b-a50d-ad6e2cbeebb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([14086, 2816]),\n",
       " torch.Size([2, 15996]),\n",
       " torch.Size([10000, 5]),\n",
       " torch.Size([10000]))"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x.shape, data.edge_index.shape, data.edge_attr.shape, data.edge_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "51898fe4-6599-44fb-b5ea-da8e0eabd790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "4fd46973-f249-41d5-bd91-65e8a6755f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_split(data, val_ratio=0.1, test_ratio=0.1, seed=42):\n",
    "    assert hasattr(data, 'edge_label'), \"data.edge_label 不存在，无法划分训练集\"\n",
    "    \n",
    "    num_edges = data.edge_label.size(0)\n",
    "    indices = list(range(num_edges))\n",
    "\n",
    "    # 1. 划分 train / val+test\n",
    "    train_idx, temp_idx = train_test_split(indices, test_size=val_ratio + test_ratio, random_state=seed)\n",
    "    # 2. 再划分 val / test\n",
    "    val_size = val_ratio / (val_ratio + test_ratio)\n",
    "    val_idx, test_idx = train_test_split(temp_idx, test_size=1 - val_size, random_state=seed)\n",
    "\n",
    "    # 3. 创建划分后的边索引、特征、标签\n",
    "    train_idx = torch.tensor(train_idx)\n",
    "    val_idx = torch.tensor(val_idx)\n",
    "    test_idx = torch.tensor(test_idx)\n",
    "\n",
    "    data.train_pos_edge_index = data.edge_index[:, train_idx]\n",
    "    data.train_edge_attr = data.edge_attr[train_idx]\n",
    "    data.train_edge_label = data.edge_label[train_idx]\n",
    "\n",
    "    data.val_pos_edge_index = data.edge_index[:, val_idx]\n",
    "    data.val_edge_attr = data.edge_attr[val_idx]\n",
    "    data.val_edge_label = data.edge_label[val_idx]\n",
    "\n",
    "    data.test_pos_edge_index = data.edge_index[:, test_idx]\n",
    "    data.test_edge_attr = data.edge_attr[test_idx]\n",
    "    data.test_edge_label = data.edge_label[test_idx]\n",
    "\n",
    "    print(f\"数据划分完成：Train {len(train_idx)}, Val {len(val_idx)}, Test {len(test_idx)}\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "4fdf99ad-c3de-47a6-9ace-4607bc9d1645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据划分完成：Train 8000, Val 1000, Test 1000\n"
     ]
    }
   ],
   "source": [
    "data = prepare_data_split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "13425bea-c73b-4330-9436-af987176cdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, edge_feat_dim, dropout=0.3):\n",
    "        super().__init__()\n",
    "        # 两层 GCN\n",
    "        self.gcn1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.norm1 = nn.LayerNorm(hidden_channels)\n",
    "        self.gcn2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.norm2 = nn.LayerNorm(hidden_channels)\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # 用于边上的评分预测：拼接两端节点表示 + 边特征\n",
    "        self.edge_mlp = nn.Sequential(\n",
    "            nn.Linear(2 * hidden_channels + edge_feat_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        # 节点嵌入\n",
    "        x = self.gcn1(x, edge_index)\n",
    "        x = self.norm1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.gcn2(x, edge_index)\n",
    "        x = self.norm2(x)\n",
    "\n",
    "        # 提取每条边两端的节点表示\n",
    "        src, dst = edge_index  # 两端的索引\n",
    "        edge_input = torch.cat([x[src], x[dst], edge_attr], dim=1)\n",
    "\n",
    "        # 预测评分\n",
    "        return self.edge_mlp(edge_input).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "6917fee8-d0c5-42db-9d0d-c16bbfe18ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN(in_channels=2816, hidden_channels=256, edge_feat_dim=5).to(device)\n",
    "data = data.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "86f83a84-f599-4ba2-b0c4-06a283dfef99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, optimizer, criterion):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 前向传播：使用训练边\n",
    "    out = model(data.x, data.train_pos_edge_index, data.train_edge_attr)\n",
    "\n",
    "    # 计算损失\n",
    "    loss = criterion(out, data.train_edge_label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, data, criterion):\n",
    "    model.eval()\n",
    "\n",
    "    # 验证集\n",
    "    val_out = model(data.x, data.val_pos_edge_index, data.val_edge_attr)\n",
    "    val_loss = criterion(val_out, data.val_edge_label).item()\n",
    "    val_rmse = val_loss ** 0.5\n",
    "\n",
    "    # 测试集\n",
    "    test_out = model(data.x, data.test_pos_edge_index, data.test_edge_attr)\n",
    "    test_loss = criterion(test_out, data.test_edge_label).item()\n",
    "    test_rmse = test_loss ** 0.5\n",
    "\n",
    "    return val_rmse, test_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "82d342f4-3a91-4b82-85aa-0da5359b96a8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 | Loss: 0.6405 | Val RMSE: 1.4487 | Test RMSE: 1.3866\n",
      "Epoch 200 | Loss: 0.3767 | Val RMSE: 1.5022 | Test RMSE: 1.4324\n",
      "Epoch 300 | Loss: 0.2483 | Val RMSE: 1.5054 | Test RMSE: 1.4380\n",
      "Epoch 400 | Loss: 0.1625 | Val RMSE: 1.4799 | Test RMSE: 1.4252\n",
      "Epoch 500 | Loss: 0.1284 | Val RMSE: 1.4862 | Test RMSE: 1.4376\n",
      "Epoch 600 | Loss: 0.1179 | Val RMSE: 1.4970 | Test RMSE: 1.4464\n",
      "Epoch 700 | Loss: 0.1043 | Val RMSE: 1.4962 | Test RMSE: 1.4517\n",
      "Epoch 800 | Loss: 0.0971 | Val RMSE: 1.4958 | Test RMSE: 1.4538\n",
      "Epoch 900 | Loss: 0.0857 | Val RMSE: 1.4960 | Test RMSE: 1.4596\n",
      "Epoch 1000 | Loss: 0.0834 | Val RMSE: 1.4963 | Test RMSE: 1.4581\n",
      "Epoch 1100 | Loss: 0.0787 | Val RMSE: 1.5170 | Test RMSE: 1.4638\n",
      "Epoch 1200 | Loss: 0.0720 | Val RMSE: 1.5118 | Test RMSE: 1.4709\n",
      "Epoch 1300 | Loss: 0.0679 | Val RMSE: 1.4988 | Test RMSE: 1.4562\n",
      "Epoch 1400 | Loss: 0.0622 | Val RMSE: 1.5203 | Test RMSE: 1.4763\n",
      "Epoch 1500 | Loss: 0.0629 | Val RMSE: 1.5026 | Test RMSE: 1.4558\n",
      "Epoch 1600 | Loss: 0.0596 | Val RMSE: 1.5060 | Test RMSE: 1.4565\n",
      "Epoch 1700 | Loss: 0.0596 | Val RMSE: 1.5143 | Test RMSE: 1.4754\n",
      "Epoch 1800 | Loss: 0.0560 | Val RMSE: 1.4912 | Test RMSE: 1.4396\n",
      "Epoch 1900 | Loss: 0.0557 | Val RMSE: 1.4966 | Test RMSE: 1.4434\n",
      "Epoch 2000 | Loss: 0.0532 | Val RMSE: 1.5164 | Test RMSE: 1.4678\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 2001):\n",
    "    loss = train(model, data, optimizer, criterion)\n",
    "    if epoch % 100 == 0:\n",
    "        val_rmse, test_rmse = evaluate(model, data, criterion)\n",
    "        print(f\"Epoch {epoch:03d} | Loss: {loss:.4f} | Val RMSE: {val_rmse:.4f} | Test RMSE: {test_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014d92b6-f228-46a4-8f09-abeb1ac30901",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
